{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5933d12-fb39-40b2-9559-1c4f45d3dae7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Step 1: Capture all relevant documents from a single Common Crawl release\n",
    "* To collect data from *N* releases, run the notebook *N* times, modifying the release name in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2956890-8c2a-48fb-90c2-95a181b126e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import warcio\n",
    "\n",
    "# For parallel_apply() in pandas\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaaef1b-4f5a-47f5-9f9e-03ecd826a3fc",
   "metadata": {},
   "source": [
    "### What release are we interested in?\n",
    "* Use the dropdown to see all available releases from 2008: https://commoncrawl.org/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6931051d-c730-42db-9f82-b51e8e7b3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "release = 'CC-MAIN-2024-10'\n",
    "#release = 'CC-MAIN-2023-50'\n",
    "#release = 'CC-MAIN-2023-40'\n",
    "#release = 'CC-MAIN-2023-23'\n",
    "#release = 'CC-MAIN-2023-14'\n",
    "#release = 'CC-MAIN-2023-06'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf45b7-3921-4fb3-880e-d9fcfb9188e8",
   "metadata": {},
   "source": [
    "### Read index from the specified release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac22c760-6360-4891-b1a5-36b90fd72e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download index into a list\n",
    "index = (\n",
    "    pd.read_csv(\n",
    "        f'https://data.commoncrawl.org/crawl-data/{release}/cc-index-table.paths.gz',\n",
    "        header=None\n",
    "    )\n",
    "    .rename(columns={0: 'index_url'})\n",
    "    .query(\n",
    "        'index_url.str.contains(\"subset=warc\")'\n",
    "    )\n",
    "    .index_url.tolist()\n",
    ")\n",
    "\n",
    "# Finalise urls - we'll download from from HTTPS not S3\n",
    "index = [f'https://data.commoncrawl.org/{x}' for x in index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1c090-3b35-4ac2-aa6b-1240a794bd5f",
   "metadata": {},
   "source": [
    "### Download lists of URLs in chunks\n",
    "* Use `duckdb` to query server-side for efficiency\n",
    "* Read one index file at a time (not all at once) to minimise 503 errors\n",
    "* Saves to `./urls` folder - make sure the folder exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f308c1-fce3-49ef-98b1-b56ffa1f6192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing part 00000...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00001...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00002...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00003...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00004...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00005...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00006...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00007...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00008...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n",
      "Processing part 00009...\n",
      "100% ▕████████████████████████████████████████████████████████████▏ \n"
     ]
    }
   ],
   "source": [
    "for path in index:\n",
    "\n",
    "    part = path.split('part-')[1].split('-')[0]\n",
    "    print(f'Processing part {part}...')\n",
    "    \n",
    "    duckdb_query = f\"\"\"\n",
    "        load httpfs;\n",
    "        load parquet;\n",
    "        \n",
    "        copy (\n",
    "            select\n",
    "                url, content_mime_type, content_mime_detected,\n",
    "                warc_filename, warc_record_offset, warc_record_length\n",
    "            from\n",
    "                parquet_scan('{path}')\n",
    "            where\n",
    "                content_mime_type ilike '%gpx%'\n",
    "                or content_mime_detected ilike '%gpx%'\n",
    "                or url ilike '%.gpx'\n",
    "        ) to './urls/{release}-{part}.csv' (delimiter ',', header true);\n",
    "    \"\"\"\n",
    "\n",
    "    !duckdb -c \"{duckdb_query}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0867e-9474-4cae-9a94-94af1e93b18a",
   "metadata": {},
   "source": [
    "### Glue the chunks back together & save as CSV\n",
    "* Saves the full index for a particular release in a CSV file to `./interim/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "483321cc-265d-46e0-a8c1-21d9976dd744",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.read_csv(f'./urls/{x}', index_col='url') for x in os.listdir('./urls/') if release in x\n",
    "]).to_csv(f'./interim/urls.{release}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a63eea6-fb83-4e6f-96d9-d6e3d218b60f",
   "metadata": {},
   "source": [
    "## 📁 Capture individual documents from WARC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89212cb5-9276-485c-aa90-7dea43d3c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_csv(f'./interim/urls.{release}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23b50a06-a679-4c17-a5c1-fdb5cd2b259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_as_string(warc_file, offset, length):\n",
    "    \"\"\"\n",
    "    Retrieves a single document from the WARC file.\n",
    "    \"\"\"\n",
    "    \n",
    "    delay = 0.25 # don't overload the server\n",
    "    time.sleep(delay)\n",
    "\n",
    "    try:\n",
    "        url = f'https://data.commoncrawl.org/{warc_file}'\n",
    "        headers = {'Range': f'bytes={offset}-{offset+length-1}'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "    \n",
    "        counter = 20 # try 20 times\n",
    "        while response.status_code != 206 and counter > 0:\n",
    "            time.sleep(delay * 2)\n",
    "            response = requests.get(url, headers=headers)\n",
    "            counter -= 1\n",
    "    \n",
    "        with io.BytesIO(response.content) as stream:\n",
    "            for record in warcio.ArchiveIterator(stream):\n",
    "                output_string = record.content_stream().read()\n",
    "    \n",
    "        return output_string.decode('utf-8').strip()\n",
    "\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c709d059-6d76-4c20-a3db-a549568b44b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4837e57f05ee4124931c86f78f8b3973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2155), Label(value='0 / 2155'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 4.76 s, total: 16.1 s\n",
      "Wall time: 39min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "urls['responses'] = urls.parallel_apply(\n",
    "    lambda row: get_document_as_string(\n",
    "        row.warc_filename,\n",
    "        row.warc_record_offset,\n",
    "        row.warc_record_length\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d45df-95a2-470c-9b0b-119272e59d1b",
   "metadata": {},
   "source": [
    "### Save dataframe as feather with file content as string\n",
    "* Saves to `./interim/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "653725e6-1cc7-4da7-83a0-7b511d71e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls.to_feather(f'./interim/urls.{release}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa5b93-a686-490f-9067-ef1cf4eabd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
